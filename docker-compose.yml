services:
  codebase-analyzer:
    build: .
    container_name: codebase-ai-analyzer
    volumes:
      # Mount the app directory
      - ./app:/app/codebase:ro
      # Mount C: drive to allow access to any directory (Windows)
      - "C:/:/mnt/c:ro"
      # Persist the vector database
      - ./chroma_db:/app/chroma_db
      # Persist downloaded models (optional, saves re-download time)
      - ./huggingface_cache:/home/analyzer/.cache/huggingface
    environment:
      - PYTHONUNBUFFERED=1
      - HF_HOME=/home/analyzer/.cache/huggingface
    ports:
      - "8080:5000"
    stdin_open: true
    tty: true
    # Default command - starts the web UI
    command: ["python3", "web_ui.py"]
    
    # For GPU support (optional, uncomment if you have NVIDIA GPU)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]